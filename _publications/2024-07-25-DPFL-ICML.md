---
title: "Decentralized Personalized Federated Learning"
collection: workshop
permalink: /publication/2024-07-25-DPFL-ICML
date: 2025-07-25
venue: 'International Conference on Machine Learning (WiML Workshop)'
paperurl: 'https://arxiv.org/abs/2406.06520'
category: "workshop"

---
Salma Kharrat, Marco Canini, Samuel Horvath  

## Abstract
This work addresses the challenges of data heterogeneity and communication constraints in decentralized federated learning (FL). We introduce decentralized personalized FL (DPFL), a bi-level optimization framework that enhances personalized FL by leveraging combinatorial relationships among clients, enabling fine-grained and targeted collaborations. By employing a constrained greedy algorithm, DPFL constructs a collaboration graph that guides clients in choosing suitable collaborators, enabling personalized model training tailored to local data while respecting a fixed and predefined communication and resource budget. Our theoretical analysis demonstrates that the proposed objective for constructing the collaboration graph yields superior or equivalent performance compared to any alternative collaboration structures, including pure local training. Extensive experiments across diverse datasets show that DPFL consistently outperforms existing methods, effectively handling non-IID data, reducing communication overhead, and improving resource efficiency in real-world decentralized FL scenarios. 

[[PAPER PDF]](https://arxiv.org/pdf/2406.06520)