---
title: "Optimized Client Participation in Federated Learning"
collection: workshop
permalink: /publication/2023-10-09
date: 13-02-2024
venue: 'International Symposium on Distributed Computing'
paperurl: 'https://arxiv.org/abs/2302.06599'
category: "workshop"

---
Fares Fourati, Salma Kharrat, Vaneet Aggarwal, Mohamed-Slim Alouini, & Marco Canini 

## Abstract
Federated learning, an emerging machine learning paradigm, enables clients to collaboratively train a model without exchanging local data. Clients participating in the training process significantly impact the convergence rate, learning efficiency, and model generalization. We propose a novel approach, client filtering, to improve model generalization and optimize client participation and training. The proposed method periodically filters available clients to identify a subset that maximizes a combinatorial objective function with an efficient greedy filtering algorithm. Thus, the clients are assessed as a combination rather than individually. We theoretically analyze the convergence of federated learning with \textit{client filtering} in heterogeneous settings and evaluate its performance across diverse vision and language tasks, including realistic scenarios with time-varying client availability. Our empirical results demonstrate several benefits of our approach, including improved learning efficiency, faster convergence, and up to 10\% higher test accuracy than training without client filtering.

[[PAPER PDF]](https://arxiv.org/pdf/2302.06599), [[Code]](https://github.com/salmakh1/FilFL)